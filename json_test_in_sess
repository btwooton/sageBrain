{
'conference': u'IEEE Transactions on Visualization and Computer Graphics', 'citationsList': False,
'author': [
    '{
        "Affiliation":"RMIT University",
        "Author":"Jing Yang",
        "Citations":8780,
        "Email":"@rmit.edu.au",
        "Exists":true,
        "Hindex":null,
        "Hindex5y":null,
        "I10index":null,
        "I10index5y":null,
        "ID":"BFXGkagAAAAJ",
        "Interests":"[u\'Construction management\']",
        "Name":"Rebecca Jing Yang",
        "Papers_in_collection":5,
        "Picture":"https:\\/\\/scholar.google.com\\/citations?view_op=small_photo&user=BFXGkagAAAAJ&citpid=2",
        "publications":null
    }',
    '{
        "Affiliation":"False",
        "Author":"Daniel Hubball",
        "Citations":0,
        "Email":"False",
        "Exists":false,
        "Hindex":0.0,
        "Hindex5y":0.0,
        "I10index":0.0,
        "I10index5y":0.0,
        "ID":"False",
        "Interests":"False",
        "Name":"False",
        "Papers_in_collection":5,
        "Picture":"False",
        "publications":0.0
    }',
    '{
        "Affiliation":"Professor of Computer Science, Worcester Polytechnic Institute","Author":"Matthew O. Ward",
        "Citations":6906,
        "Email":"@cs.wpi.edu",
        "Exists":true,
        "Hindex":null,
        "Hindex5y":null,
        "I10index":null,
        "I10index5y":null,
        "ID":"EMOe15MAAAAJ",
        "Interests":"[u\'data and information visualization\', u\'visual analytics\']","Name":"Matthew Ward",
        "Papers_in_collection":5,
        "Picture":"https:\\/\\/scholar.google.com\\/citations?view_op=small_photo&user=EMOe15MAAAAJ&citpid=2",
        "publications":null
    }',
    '{
        "Affiliation":"False",
        "Author":"Elke A. Rundensteiner",
        "Citations":0,
        "Email":"False",
        "Exists":false,
        "Hindex":0.0,
        "Hindex5y":0.0,
        "I10index":0.0,
        "I10index5y":0.0,
        "ID":"False",
        "Interests":"False",
        "Name":"False",
        "Papers_in_collection":5,
        "Picture":"False",
        "publications":0.0
    }',
    '{
        "Affiliation":"False",
        "Author":"William Ribarsky",
        "Citations":0,
        "Email":"False",
        "Exists":false,
        "Hindex":0.0,
        "Hindex5y":0.0,
        "I10index":0.0,
        "I10index5y":0.0,
        "ID":"False",
        "Interests":"False",
        "Name":"False",
        "Papers_in_collection":5,
        "Picture":"False",
        "publications":0.0
    }
'],
'globalID': u'7N8IFD7Z',
'title': u'Value and Relation Display: Interactive Visual Exploration of Large Data Sets with Hundreds of Dimensions',
'url': u'http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4135655', 'text': u'See\tdiscussions,\tstats,\tand\tauthor\tprofiles\tfor\tthis\tpublication\tat:\thttps://www.researchgate.net/publication/6451414\n\nValue\tand\tRelation\tDisplay:\tInteractive\tVisual\nExploration\tof\tLarge\tData\tSets\twith\tHundreds\tof\nDimensions\n\nArticle\t\tin\t\tIEEE\tTransactions\ton\tVisualization\tand\tComputer\tGraphics\t\xb7\tMay\t2007\n\nDOI:\t10.1109/TVCG.2007.1010\t\xb7\tSource:\tPubMed\n\nCITATIONS\n37\n\n5\tauthors,\tincluding:\n\nREADS\n78\n\nMatthew\tWard\nWorcester\tPolytechnic\tInstitute\n\n133\tPUBLICATIONS\t\t\t3,082\tCITATIONS\t\t\t\n\nElke\tRundensteiner\nWorcester\tPolytechnic\tInstitute\n\n567\tPUBLICATIONS\t\t\t7,531\tCITATIONS\t\t\t\n\nSEE\tPROFILE\n\nSEE\tPROFILE\n\nAll\tcontent\tfollowing\tthis\tpage\twas\tuploaded\tby\tMatthew\tWard\ton\t12\tMarch\t2014.\n\nThe\tuser\thas\trequested\tenhancement\tof\tthe\tdownloaded\tfile.\n\n\x0cValue and Relation Display: Interactive Visual\nExploration of Large Datasets with Hundreds of\n\nDimensions\n\n1\n\nJing Yang\n\nDept of Computer Science\n\nUNC Charlotte\n\njyang13@uncc.edu\n\nDaniel Hubball\nDept of Computer Science\nUniversity of Wales Swansea\n\ncsdan@swansea.ac.uk\n\nMatthew Ward\nDept of Computer Science\n\nWorcester Polytechnic Institute\n\nmatt@cs.wpi.edu\n\nElke Rundensteiner\nDept of Computer Science\n\nWorcester Polytechnic Institute\n\nrundenst@cs.wpi.edu\n\nWilliam Ribarsky\nDept of Computer Science\n\nUNC Charlotte\n\nribarsky@uncc.edu\n\nAbstract\u2014 Few existing visualization systems can handle large\ndatasets with hundreds of dimensions, since high dimensional\ndatasets cause clutter on the display and large response time in\ninteractive exploration. In this paper, we present a signi\ufb01cantly\nimproved multi-dimensional visualization approach named Value\nand Relation (VaR) display that allows users to effectively and\nef\ufb01ciently explore large datasets with several hundred dimen-\nsions. In the VaR display, data values and dimension relationships\nare explicitly visualized in the same display by using dimension\nglyphs to explicitly represent values in dimensions and glyph\nlayout to explicitly convey dimension relationships. In particular,\npixel-oriented techniques and density-based scatterplots are used\nto create dimension glyphs to convey values. Multi-dimensional\nscaling, Jigsaw map hierarchy visualization techniques, and\nan animation metaphor named Rainfall are used to convey\nrelationships among dimensions. A rich set of interaction tools\nhave been provided to allow users to interactively detect patterns\nof interest in the VaR display. A prototype of the VaR display\nhas been fully implemented. The case studies presented in this\npaper show how the prototype supports interactive exploration of\ndatasets of several hundred dimensions. A user study evaluating\nthe prototype is also reported in this paper.\n\nIndex Terms\u2014 Multi-dimensional visualization, high dimen-\n\nsional datasets, visual analytics.\n\ndatasets in the Information Visualization \ufb01eld. They include:\n(cid:129) Using condensed displays to provide as much information\nas possible to users. Typical approaches include pixel-\noriented techniques [12], [13] and density-based displays\n[9], [24]. For example, in pixel-oriented techniques, infor-\nmation is so condensed that each pixel presents a single\ndata value.\n\n(cid:129) Examining relationships among dimensions to discover\nlower dimensional spaces with signi\ufb01cant features. Ex-\nample approaches include ranking low dimensional pro-\njections by their features such as linear relationships [19],\nand placing dimensions in a layout revealing their rela-\ntionships to help users construct meaningful subspaces\n[28].\n\n(cid:129) Providing a rich set of interactions to allow users to\nexplore datasets from multiple coordinated views. In\nthese views, different subsets of dimensions and/or data\nitems can be examined at different levels of detail us-\ning different visualization techniques. Examples of such\napproaches include the Hierarchical Parallel Coordinates\n[10] and the VIS-5D system [11].\n\nI. INTRODUCTION\n\nLarge datasets with hundreds of dimensions are common\nin applications such as image analysis, \ufb01nance, bioinformatics\nand anti-terrorism. For example, in order to detect the semantic\ncontents of large image collections, it is common to analyze\nhundreds of low level visual attributes of the images. It is\na challenge to make decisions based on these datasets, since\nthey are hard to analyze due to the dimensionality curse [5],\ni.e., the lack of data separation in high dimensional space.\nUsing multi-dimensional visualization techniques to present\nthis data to analysts and allowing them to interactively explore\nand understand the datasets are an important approach to\naddressing this challenge. However, most traditional multi-\ndimensional visualization techniques suffer from visual clutter\nand only scale up to tens of dimensions. Up to now, few multi-\ndimensional visualization systems have claimed to be scalable\nto datasets with hundreds of dimensions. In this paper, we\npresent such a system, called the Value and Relation (VaR)\ndisplay, which is an improved version of a technique reported\nin an earlier paper [27].\n\nOur work is based on multiple concepts proposed and\nexplored in prior efforts toward visual exploration of large\n\nThe concepts above are signi\ufb01cant features of the VaR\ndisplay since its initial version [27]. In the \ufb01rst version (see\n\ufb01gures 1a and b), pixel-oriented displays were used to show\ndata values and group them into dimension glyphs representing\nindividual dimensions. The dimension glyphs were then po-\nsitioned on the screen using a fast Multi-dimensional scaling\n(MDS) algorithm [4] according to dimension correlations to\nreveal their inter-relationships (dimension correlation is used\nsince it is a typical measure of dimension relationships, but\nother relationship measures can also be used). A rich set\nof interactions were provided to facilitate navigation in the\ndisplay and generate lower dimensional spaces of interest. To\ndifferentiate the \ufb01rst version from the improved version, we\ncall it the Pixel MDS VaR display.\n\nIn the improved version of VaR presented in this paper,\nthese features are signi\ufb01cantly strengthened. A density-based\nscatterplot [9], [24] has been added to the system as an alter-\nnate approach to generating dimension glyphs. A Jigsaw map\nlayout [23] and the Rainfall metaphor have been added into the\nsystem as alternate dimension glyph layout approaches. The\nnew version also supports a broader range of interaction tools\nthan the original version, including a new data item selection\n\n\x0c2\n\nFig. 1.\n(a) Illustration of the VaR display. On the left is the spreadsheet of a 4-dimensional dataset with each column representing a dimension. On the\nbottom is a matrix that records the pair-wise relationships (such as correlations) among the dimensions. In the middle is the glyph of the fourth dimension.\nOn the right is the VaR display of the dataset. (b) The Pixel MDS VaR display of the Image-89 dataset (89 dimensions, 10,417 data itmes). (c) The X-Ray\nscatterplot MDS VaR display of the same dataset.\n\nand highlighting tool. The labeling issue, which was ignored in\nthe initial version, is addressed in this version. A case study is\nincluded in this paper involving the visual analysis of a dataset\nwith 838 dimensions. A user study comparing the VaR display\nwith the rank-by-feature framework [19], [20] is also reported.\nThis paper is organized as follows. Section II reviews\nrelated work. Section III brie\ufb02y introduces the original Pixel\nMDS VaR display. Section IV presents the approach of us-\ning density-based scatterplots to generate dimension glyphs.\nSection V describes the new Jigsaw and Rainfall dimension\nglyph layout strategies. Section VI summarizes the correlation\ncalculation algorithm used in the VaR display. Section VII\npresents the interaction tools. Section VIII addresses the\nlabeling issue. Section IX describes the implementation of\nthe VaR display and addresses the scalability issue.Section X\ndiscusses visual exploration approaches with the VaR display.\nSection XI presents a case study and Section XII presents\na user study for the VaR display. Section XIII presents our\nconclusions and future work.\n\nII. RELATED WORK\n\nMany techniques exist for generating condensed displays\nfor large datasets. The work most related to our work is pixel-\noriented techniques and scatterplots. Pixel-oriented visualiza-\ntion techniques [12], [13] are a family of multi-dimensional\ndisplay techniques that map each data value to a pixel on\nthe screen and arrange the pixels into subwindows to convey\nrelationships. The patterns of the subwindows may reveal\nclusters, trends, and anomalies. Pixel-oriented techniques are\none among several options to create the dimension glyph in\nthe VaR display.\n\nScatterplots visualize 2-D datasets or 2-D projections of\nmulti-dimensional datasets. In a scatterplot, there is a hori-\nzontal axis and a vertical axis, which are associated with two\ndimensions (X and Y). The data items are plotted onto the\ndisplay according to their coordinates on X and Y. Scatterplots\nare widely used since they provide rich information about the\n\nrelationship between two dimensions, such as strength, shape\n(line, curve, etc), direction (positive or negative), and presence\nof outliers [18]. Density-based scatterplots [24], [9] scale to\nlarge datasets by using intensity of the spot in a scatterplot\nto indicate the data density in that spot. We use the density-\nbased scatterplot as an option for generating the dimension\nglyph and treat the areas with no data items in a scatterplot in\na different way from existing approaches due to the possible\noverlaps among the scatterplots.\n\nScatterplots of multi-dimensional datasets are often orga-\nnized together to show multiple 2D projections of the datasets.\nScatterplot matrices [7] organize the scatterplots of all N x (N-\n1)/2 2-D projections of an N-dimensional dataset into a matrix.\nScatterplot matrices easily get cluttered when the number of\ndimensions increases. Rather than displaying all 2D projec-\ntions, we display N scatterplots between all dimensions and\na focus dimension and position them in a manner conveying\ndimension relationships in our density-based scatterplot VaR\noption.\n\nThere exist multiple visualization approaches to examining\nrelationships among dimensions to discover lower dimen-\nsional spaces with signi\ufb01cant features. The rank-by-feature\nframework [19] ranks 1D or 2D axis-parallel projections of\nmulti-dimensional datasets using statistical analysis to help\nusers detect 1D or 2D projections with desired features such\nas linearly related dimensions. [16] visualizes correlations\nbetween each pair of dimensions in a matrix and allows users\nto interactively select dimensions from the matrix to con-\nstruct lower dimensional spaces. The interactive hierarchical\ndimension reduction approach [28] visually conveys dimension\nrelationships using a dimension hierarchy to facilitate lower\ndimensional space construction. The VaR display is different\nfrom these approaches since it integrates data value visual-\nization with dimension relationship visualization in the same\ndisplay to use screen space more ef\ufb01ciently.\n\nMulti-dimensional Scaling (MDS) [4], [15] is an itera-\ntive non-linear optimization algorithm for projecting multi-\n\n\x0cdimensional data down to a reduced number of dimensions.\nIt is often used to convey relationships among data items\nof a multi-dimensional dataset. For example, IN-SPIRE [25]\nuses MDS to map data items from a document dataset to\na 2D space. It generates a Galaxies display as a spatial\nrepresentation of relationships within the document collection.\nIn our approach, MDS is used in a different way, namely to\nconvey relationships among dimensions rather than data items.\nThe Jigsaw map [23] is a recent space \ufb01lling hierarchy\nlayout method. By placing the leaf nodes of a hierarchy into\na 1D layout using a depth \ufb01rst traversal and mapping the\n1D layout\ninto a rectangular 2D mesh using space-\ufb01lling\ncurves, this method creates hierarchy displays of nicely shaped\nregions, good continuity and stability. When all leaf nodes are\nof the same size, a Jigsaw map can draw all leaf nodes without\nany distortion in shape, namely, they can be all equal-sized\nsquares. This property of the Jigsaw map makes it a perfect\noption for us to lay out dimensions organized into a hierarchy\non a 2D mesh, with each dimension drawn as a square glyph.\nThe similarity based dimension arrangement proposed in\n[1] also addressed the problem of arranging pixel oriented\nsubwindows (dimensions) on a 2D mesh. It aimed to place\nsimilar dimensions close to each other on the 2D mesh. The\nJigsaw map dimension layout is different in that it aims to\nuse the dimension layout to convey the hierarchical structure\namong the dimensions. As a consequence, not only similar\ndimensions but also outlier dimensions are revealed.\n\n[29] presents a multi-dimensional visualization technique\ncalled Dust & Magnet. It represents dimensions as magnets\nand data items as dust particles and attracts dust particles using\nmagnets to reveal data item values in the dimensions. The\nRainfall metaphor proposed in this paper was inspired by Dust\n& Magnet. The difference is that the Rainfall metaphor attracts\ndimensions using dimensions, while Dust & Magnet attracts\ndata items using dimensions.\n\nIII. PIXEL MDS VAR DISPLAY\n\nFigure 1a illustrates the approach to generating a Pixel\nMDS VaR display. First, a dimension glyph, called a glyph in\nshort, is generated to represent data values in each dimension,\ni.e., values in the same column in the spreadsheet, using\npixel oriented techniques [13]. In particular, each value is\nrepresented by a pixel whose color indicates a high or low\nvalue, and pixels representing values from the same dimension\nare grouped together to form a glyph. In a glyph, each pixel\noccupies a unique position without overlap. In the original\nversion, a spiral pixel layout was used. Rows in the spreadsheet\nare ordered according to their values in one dimension (Note:\nactually any 1D order can be used). Data values in each\ncolumn are positioned into a spiral according to this order. In\nall glyphs, pixels representing values in the same row occupy\nthe same position so that glyphs can be associated with each\nother.\n\nSecond, the correlations among the dimensions are cal-\nculated and recorded into an N x N matrix (where N is\nthe dimensionality of the dataset). In order to calculate the\ncorrelations, different approaches can be used according to\n\n3\n\ndifferent purposes. For example, if users are most interested\nin linearly related dimensions, Pearson\u2019s correlation coef\ufb01-\ncient can be used to capture the linear relationships among\ndimensions. We proposed a scalable and \ufb02exible correlation\ncalculation algorithm [27] and applied it in the VaR display.\nWe will brie\ufb02y introduce it in Section VI for the purpose of\ncompleteness.\n\nThird, the N x N relationship matrix is used to generate N\npositions in a 2-D space, one position for each dimension. The\nproximity among the positions re\ufb02ects relationships among\nthe dimensions, i.e., closely related dimensions are spatially\nclose to each other, and unrelated dimensions are positioned\nfar way from each other. In particular, a multi-dimensional\nscaling algorithm [4] is used to create the 2-D positions upon\nthe relationship matrix.\n\nFinally, the dimension glyphs are placed in the 2-D space\nin their corresponding positions to form the VaR display.\nFigure 1b shows an example of the VaR display. It shows\nthe Image-89 dataset of 89 dimensions and 10,417 data items.\nIt is a real dataset containing 88 low level visual attributes\nand classi\ufb01cation information for 10,417 image segments\ngenerated by an image analysis approach [8]. In the \ufb01gure,\neach block is a dimension glyph and there are 89 glyphs.\nIn each glyph, data values of the dimension are mapped to\ncolors of pixels, and pixels are ordered in a spiral manner. The\ncloseness of the glyph positions reveals the correlations among\nthe dimensions calculated by the underlying algorithm. For\nexample, several clusters of closely correlated dimensions and\na few dimensions that are distinct from most other dimensions\ncan be detected from the glyph positions in Figure 1b.\n\nThe above approach can be summarized as dimension glyph\ngeneration and layout. Glyphs explicitly convey data values\nand their layout explicitly conveys dimension relationships.\nMoreover, dimension relationships are also revealed by the\npatterns of the glyphs. Similarity among glyph patterns in-\ndicates dimension relationships, whether there is a linear or\nnon-linear relationship, or they are partially correlated (such\nas dimensions for which a subset of the data items is closely\nrelated). Since humans are good at pattern recognition, the\npatterns of the glyphs provide straightforward and intuitive\ncomparison of the dimensions. On the one hand, the layout\napproach brings related dimensions close to each other to make\nthe pattern comparison easier. On the other hand, the patterns\nallow users to con\ufb01rm or refute the relationships suggested by\nthe layout using their eyes, and reveal how the dimensions are\nrelated in detail.\n\nBesides the techniques used in the original VaR display,\nthere are other approaches to creating glyphs and laying them\nout, which will be introduced in the following sections. Since\nglyph generation and layout are independent from each other,\nthey can be combined freely to form various VaR displays.\n\nIV. DIMENSION GLYPH ALTERNATIVE: X-RAY\n\nSCATTERPLOTS\n\nThe glyph generation approach used in the original VaR\ndisplay is not the only approach for creating dimension glyphs.\nFor example, different layouts of the pixels within a glyph\n\n\x0creveal different patterns. As an example, organizing pixels\ninto a calendar pattern according to the time stamps of the\ndata items can reveal time-dependant patterns among the data\nitems. Since these techniques have been widely studied in\npixel-oriented techniques [12] and they can be integrated\ninto the VaR display easily by replacing the original pixel-\noriented dimension glyph generation approach, they will not\nbe discussed in this paper. Instead, we present our work\non customizing a density-based scatterplot glyph (called an\nX-Ray glyph) generation approach. This approach has been\nintroduced into the improved version (see Figure 1c for an\nexample VaR display using the scatterplot approach).\n\nIn the VaR display, a scatterplot\n\nis generated for each\ndimension. The Y dimension of a scatterplot dimension glyph\nis the dimension it represents, while all of the glyphs have the\nsame X dimension. We choose to use the same X dimension\nsince it will be hard for users to associate different dimension\nglyphs if both X and Y dimensions change from one glyph\nto another. Although this causes information loss, users can\nalways interactively change the X dimension guided by the\nsemi-automatic selection tool (see Section VII) and their visual\nexploration (see Section XI).\n\nThe VaR display is targeted at large datasets. It is time\nconsuming to draw the projection of each data item on each\nof the N scatterplots. Also, the large number of projections\nwould clutter the glyph. In order to avoid clutter and increase\nscalability, we store each glyph as an M X M pixel matrix,\nwhere M is an adjustable integer, and divide the 2D space\nwithin the value range of the dataset into M X M equal-\nsize bins. The number of projections falling into each bin\nis recorded and translated into the color of its corresponding\npixel in the pixel matrix. In particular, the intensity of the pixel\nis proportional to data density of the area it represents.\n\nFig. 2. X-Ray Scatterplots (a) The \ufb01rst solution (b) The second solution (c)\nThe X-Ray scatterplot solution.\n\nThe \ufb01rst image (Figure 2a) we generated is disappointing,\nsince it is hard to differentiate unoccupied area (areas with\nzero data items) from areas with a few data items. In order\nto solve this problem, we assign a different hue to the pixels\nrepresenting unoccupied areas. In the image generated (Figure\n2b), there are no data items in the blue area. We then observed\nthat,\nto glyphs generated using pixel-oriented\ntechniques where every pixel represents a data value, there\nare often large contiguous unoccupied areas in a scatterplot\nglyph, especially when the X and Y dimensions are closely\nrelated. Recalling that some glyph layout approaches, such\n\nin contrast\n\n4\n\nas MDS, could cause overlaps among different glyphs, we\nmade the unoccupied areas semi-transparent so that users can\nsee hidden glyphs through the unoccupied areas of the hiding\nglyphs. Figure 2c shows this \ufb01nal solution. Since in the \ufb01gure\nthe glyphs look very much like X-Ray photos, we named\nthis VaR display the X-Ray scatterplot VaR display. To give\nusers more \ufb02exibility, we allow them to interactively choose\nthe color and transparency of the unoccupied areas. If users\ndislike the semi-transparent unoccupied areas, they are able to\nset them to opaque.\n\nV. DIMENSION LAYOUT ALTERNATIVES: JIGSAW MAP\n\nLAYOUT AND RAINFALL\n\nA. Jigsaw Map Glyph Layout\n\nThe MDS approach is effective in conveying dimension\nrelationships. However, using the MDS approach, the positions\nof two glyphs could be very close to each other if they are\nclosely related. Glyphs might overlap in this case, which is\nsometimes undesired by the users. Besides allowing the users\nto reduce overlaps in the MDS layout using interactions (see\nSection VII), we propose a Jigsaw Map dimension layout\nbased on the recently proposed Jigsaw map [23]. In this\napproach, dimensions are grouped into a dimension hierarchy.\nThe Jigsaw map, which is a space-\ufb01lling hierarchy visualiza-\ntion method, is then used to lay the dimensions on a grid.\nThis approach not only prevents glyphs from overlapping, but\nalso conveys the hierarchical structure among the dimensions.\nFigure 3 shows VaR displays with a Jigsaw layout.\n\nThe motivation of this approach is that grouping dimensions\nof high dimensional datasets into dimension hierarchies makes\nit easy to capture the relationships among the dimensions.\nIn a dimension hierarchy, dimensions are organized into a\nhierarchy of clusters. Dimensions within a cluster have closer\nrelationships among each other than with dimensions outside\nthe cluster. Clusters in different levels of the hierarchy divide\nthe dimensions into groups of different granularity. With the\ndimension relationship matrix, it is convenient to generate\na dimension hierarchy using existing hierarchical clustering\napproaches. In the hierarchy, each leaf node is a dimension in\nthe high dimensional dataset.\n\nIn order to turn the dimension hierarchy into the dimension\nlayout, we examined existing hierarchy visualization tech-\nniques. The basic requirements are 1) the layout should be\nspace ef\ufb01cient since our target is high dimensional datasets\nand 2) each dimension should be assigned a space of the\nsame size, shape and orientation since it is dif\ufb01cult for users\nto compare and associate glyphs with different sizes, shapes,\nor orientations. Since node-linked diagrams do not use space\nef\ufb01ciently, we only considered the space-\ufb01lling hierarchy\nvisualization techniques [3], [21], [23]. Among them, only\nthe Jigsaw map [23] and quantum treemaps [3] are capable\nsince all other techniques assign areas of different shapes or\norientations to leaf nodes. We chose the Jigsaw map since it\ngenerates layouts of nicely shaped regions and is stable with\nregards to changing tree structures and leaf nodes [23].\n\nTo generate the Jigsaw map layout, we \ufb01rst hierarchically\ncluster the N dimensions in a dataset based on their pair-\nwise distances (a pair of more closely related dimensions\n\n\x0c5\n\nFig. 3. The Image-838 dataset (838 dimensions, 11,413 data items). (a) The Pixel Jigsaw map VaR display with separated dimensions selected and labeled\n(b) The X-Ray scatterplot Jigsaw map VaR display with dimension Coarseness as the X dimension. The X dimension is in a pink frame and labeled. (c)\nThe X-Ray scatterplot Jigsaw map VaR display with dimension angle 135 as the X dimension. The X dimension is at the left bottom corner of the map and\ndimensions closely related to it are in red frames. (d) A zoomed in display of the selected dimensions with their labels shown.\n\nhas a smaller distance than a pair of less related dimensions)\nusing the minimum single linkage metrics [17]. Then, the N\ndimensions are ordered into a 1-D sequence according to their\npositions in the hierarchy using a depth-\ufb01rst traversal of the\nhierarchy, and then the sequence is mapped to a 2-D L x K (\nL x K >= N) mesh by applying a space-\ufb01lling curve called\nan H curve (please refer to [23] for more details). Figure 3a\nshows an example of the Jigsaw layout. In this \ufb01gure, similar\ndimensions are close to each other and signi\ufb01cant boundaries\nof groups of closely related dimensions, such as the group of\n\ndimensions in the left bottom part of the map, can be detected.\nOutlier dimensions, such as the dimensions on the left top part\nof the map, are also distinguishable since their textures look\ndifferent from their neighbors.\n\nB. Rainfall Metaphor\n\nWhen exploring a high dimensional dataset, users are often\ninterested in the relationships between a single dimension of\ninterest with all other dimensions. Beside the X-Ray scatter-\nplot, which reveals the relationships using glyph textures, we\n\n\x0c6\n\nFig. 4. The Rainfall Metaphor. (a) At the beginning of the rain. Dimensions more closely related to the dimension of interest in the bottom are falling in a\nfaster acceleration than less related dimensions. (b) The rain continues. The dimensions with different correlations to the dimension of interest are separated.\nIt can be seen that there are roughly three levels of association between the dimension of interest and other dimensions. (c) The Rain is close to its end.\nDimensions signi\ufb01cantly distinct from the dimension of interest are revealed. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels\nare ordered in a line by line (horizontal lines) manner.\n\nprovide a simple animation approach to dynamically illustrate\nthe relationships by changing glyph positions. This approach is\nnamed the Rainfall Metaphor since it imitates rain (see Figure\n4 for an example).\n\nIn the beginning of the animation, the dimension of interest\nis placed in the center bottom of the display (the ground) and\nall other dimensions (raindrops) are placed in the top of the\ndisplay (the sky). The horizontal positions of the raindrops\nare randomly generated. After the rain starts, a raindrop falls\ntoward the ground in an acceleration that is proportional to\nits correlation with the dimension of interest. Thus, a raindrop\nmoves toward the ground faster than another raindrop if it has\na closer relationship to the dimension of interest. A raindrop\nstops its movement after it hits the ground. There is a timer\nthat starts from the beginning of the rain and ends when\nall raindrops hit the ground. Users can interactively play the\nanimation by moving the slider representing the timer. Users\ncan also interactively select the dimension of interest for the\nanimation.\n\nFigure 4a-c shows some screen captures of the Rainfall\nlayout. Using this metaphor, users can focus on the relation-\nships between the dimension of interest and other dimensions,\nwithout being distracted by relationships among the other\ndimensions. In different moments of the rain, either similar\ndimensions or distinct dimensions to the dimension on the\nground attract the users\u2019 attention.\n\nVI. CORRELATION CALCULATION\n\nIn the VaR display, a binning based correlation calculation\nalgorithm is used. We only brie\ufb02y introduce it here since\nit has been presented in full detail in [27]. We claim that\nany relationship calculation algorithm can be used in the VaR\ndisplay as long as it scales to large datasets. The layout of\nthe glyphs re\ufb02ects the type of relationship calculated by the\nunderlying algorithm.\n\nIn our algorithm, distribution of the value differences (be-\ntween the different dimensions for the same data item) is\nrecorded into bins. In particular, the possible range of value\ndifferences between a pair of dimensions is divided into a\nsequence of bins. The number of data items whose value\ndifferences between these two dimensions fall into the bins is\nrecorded. For an N dimensional dataset, N x (N-1)/2 sequences\nof bins (one sequence for each pair of dimensions) are created.\nA pair of dimensions is considered to be closely related if\na large number of data items fall info a small number of\nbins (K) in its sequence. With a given K, the correlations\ncan be calculated in this way: sort the bins in the sequence\naccording to their populations, and sum up the populations\nof K bins with the highest populations. The sum divided by\nthe total population of the data items is proportional to the\ncorrelation between the dimensions. K is selected to be the\nnumber of bins that make the global variance of correlations\nfor all dimensions maximum. This algorithm scales to a large\nnumber of data items. Except for the \ufb01rst scan, which can\nbe done with minimal cost when inserting the dataset into\nthe database, its ef\ufb01ciency is only related to the number of\ndimensions.\n\nThe above algorithm is a heuristic approach whose purpose\nis to maximize the visibility of the structure of the MDS and\nJigsaw layout. There are many other optimization problems\nin the VaR display, such as selecting a dimension ordering\nthe pixel-oriented display in the initial view to provide the\nmaximum information to users at a \ufb01rst glance. A detailed\ndiscussion of such problems is presented in [27] and not\nrepeated here.\n\nVII. INTERACTIVE TOOLS IN THE VAR DISPLAY\n\nA rich set of interaction tools has been developed for the\nVaR display. Navigation tools help users reduce clutter in the\ndisplay and discover information about the dataset. Automatic\nand manual dimension selection tools allow users to perform\n\n\x0chuman-driven dimension reduction by selecting subsets of\ndimensions for further exploration in the VaR display as well\nas other multi-dimensional visualizations. Data item selection\ntools allow users to select subsets of data items for further\nexploration. In addition, the data item masking tool allows\nusers to examine details of selected data items within the\ncontext of unselected data items.\n\nMost of the interactive tools make no special assumption\nabout the glyph positioning and generation strategies, i.e., they\ncan be applied to any realization of the VaR display. These\ntools are called general tools. Unless speci\ufb01cally noted, an in-\nteraction tool is a general tool in the following sections, where\ndetails of each navigation and selection tool are presented.\n\nA. Tools for Glyph Layout\n\nThe MDS dimension layout causes overlaps among the\nglyphs. Overlaps emphasize close relationships among the\ndimensions because glyphs overlap only if their dimensions\nare closely related. However, overlaps can prevent a user\nfrom seeing details of an overlapped glyph. We provide the\nfollowing operations to overcome this problem (see [27] for\nmore detail).\n\n(cid:129) Showing Names: By putting the cursor on the VaR\ndisplay, the dimension names of all glyphs under the\ncursor position are shown in a message bar. Thus a user\ncan be aware of the existence of glyphs hidden by other\nglyphs.\n\n(cid:129) Layer Reordering: With a mouse click, a user can force\na glyph to be displayed in front of the others. In this\nway he/she can view details of a glyph that is originally\noverlapped. Users can also randomly change the ordering\nof all dimension glyphs by clicking a button in the control\nframe. In addition, selected dimensions are automatically\nbrought to the front of the display.\n\n(cid:129) Manual Relocation: By holding the control key, a user\ncan drag and drop a glyph to whatever position he/she\nlikes. In this way a user can separate overlapping glyphs.\n(cid:129) Extent Scaling: Extent scaling allows a user to interac-\ntively decrease the sizes of all the glyphs proportionally to\nreduce overlaps, or to increase them to see larger glyphs.\n(cid:129) Dynamic Masking: Dynamic masking allows users to\nhide the glyphs of unselected dimensions from the VaR\ndisplay.\n\n(cid:129) Automatic Shifting: This operation automatically re-\nduces the overlaps among the glyphs by slightly shift-\ning the positions of the glyphs. There are many more\nadvanced overlap reducing algorithms that can be used,\nsuch as those listed in [22].\n\n(cid:129) Distortion: Users can interactively enlarge the size of\nsome glyphs while keeping the size of all other glyphs\n\ufb01xed. In this way users are allowed to examine details\nof patterns in the enlarged glyphs within the context\nprovided by the other glyphs.\n\n(cid:129) Zooming and Panning: Users can zoom in, zoom out\nand pan the VaR display. For example, in order to reduce\noverlaps, sometimes the size of the glyphs has to be set\nvery small when there are a large number of dimensions.\n\n7\n\nZooming into the display will enlarge the glyphs so that\nthe user can have a clear view of the patterns in the\nglyphs.\n\n(cid:129) Re\ufb01ning: A re\ufb01ned VaR display can be generated for\na selected subset of dimensions and a selected subset\nof data items. The selected dimensions and data items\nare treated as a new dataset. The relationship calculation,\nglyph generation and positioning are applied to the new\ndataset.\n\nB. Tools for Glyph Regeneration\n\nIn the Pixel-Oriented dimension glyphs, the dimension used\nto sort the data items affects the glyph patterns signi\ufb01cantly.\nClusters in subspaces including this dimension can be easily\ndetected while clusters in other subspaces are not. Similarly, in\nthe X-Ray scatterplot dimension glyphs, relationships between\nother dimensions and the X dimension are easier to detect\nthan relationships among other dimensions. We allow users to\ninteractively select the sorting dimension in the pixel-oriented\nmode and the X dimension in the X-Ray scatterplot mode\nby clicking the mouse button on the glyph of the desired\ndimension or selecting from a combo-box.\n\nIn addition, a comparing mode can be used in the pixel-\noriented glyphs in order to compare the dimensions with a\ndimension of interest. In this mode, except the glyph of the\nbase dimension, the pixels of all other glyphs will be colored\naccording to the differences between the values of the base\ndimension and their dimensions. A \ufb01gure of the comparing\nmode can be found in [27].\n\nC. Dimension Selection Tools\n\nDimension selection tools enable users to select dimen-\nsions of interest for further exploration using other multi-\ndimensional visualization techniques. They can also be used\nas a \ufb01lter to reduce the number of glyphs displayed in a VaR\ndisplay, since we allow users to hide glyphs of unselected\ndimensions using dynamic masking (see Section VII-A). The\nselection tools we provide to users include automatic selec-\ntion tools for closely related dimensions and well separated\ndimensions, in addition to manual selection.\n\nThe automatic selection tool for related dimensions\ntakes a user-assigned dimension and correlation threshold as\ninput. Here we assume that a pair of more closely related\ndimensions has a larger correlation measure than a pair of\nless related dimensions. Users pick the assigned dimension by\nclicking its glyph and adjust the threshold through a slider. The\ntool automatically selects all dimensions whose correlation\nmeasures to the input dimension are larger than the threshold\nby traversing the dimension relationship matrix. This tool\nenables the users to select a set of closely related dimensions.\nThe automatic selection tool for separated dimensions\ntakes a user-assigned dimension and correlation threshold\nas input and returns a set of dimensions that describe the\nmajor features of the dataset. The assigned dimension will\nbe included in the returned set of dimensions. Between each\npair of dimensions in the result set, the correlation measure is\nsmaller than the threshold. For any dimension that is not in\n\n\x0c8\n\nFig. 5. Masking of Unselected Data Items. Unselected data items are covered by a mask with adjustable color and transparency. (a) No mask or fully\ntransparent mask. (b) Opaque mask. (b) Semi-transparent mask. The dataset is the Image-89 dataset. The glyphs are pixel-oriented glyphs (pixels are ordered\nin a line by line (vertical lines) manner.\n\nthe result set, there is at least one dimension in the result set\nwhose correlation measure with it is larger than the threshold.\nUsing this tool, a user is able to select a set of dimensions\nto construct a lower dimensional subspace revealing the major\nfeatures of the dataset without much redundancy. In Figure 1b\nseparated dimensions selected automatically are labeled.\n\nThe following algorithm can be used for automatic selection\n\nof separated dimensions:\n\n1) Get the assigned dimension and the selection threshold.\n2) Set the assigned dimension as \u201cselected\u201d and all other\n\ndimensions as \u201cunselected\u201d.\n\n3) Find all unselected dimensions whose correlation mea-\nsures to all existing selected dimensions are smaller than\nthe threshold. Mark them as \u201ccandidates\u201d.\n\n4) If there is no candidate dimension, go to step 5. Else, set\none candidate dimension as \u201cselected\u201d and every other\ncandidates as \u201cunselected\u201d. Go back to step 3.\n\n5) Return all dimensions marked as \u201cselected\u201d.\nIt is interesting that it is not de\ufb01ned how to pick one dimen-\nsion among the candidate dimensions in step 4. Thus it can\nbe customized according to the task of interest. For example,\nin Section VIII, this approach is customized to reduce the\nclutter among the labels of the selected dimensions for a good\nlabeling result. Here we present another customization.\n\nWhen users start to explore an unknown dataset, it is often\ndesired to \ufb01nd dimension groups containing large numbers of\nclosely related dimensions. Thus a heuristic approach can be\nused in step 4: setting a threshold, for each candidate dimen-\nsion counting the number of dimensions having correlation\nmeasures to it that are larger than the threshold, and selecting\nthe dimension with the highest count. Using this approach\ndimensions with a larger number of closely related dimensions\nhave higher priority to be selected.\n\nManual selection allows a user to manually select a dimen-\nsion by clicking its corresponding glyph. The user can unselect\nthe dimension by clicking the glyph again. The combination of\nmanual and automatic selection makes the selection operation\n\nboth \ufb02exible and easy to use.\n\nD. Data Item Selection and Masking Tools\n\nRather than allowing a user to select data items directly from\nthe glyphs in the VaR display (which is hard when glyphs\nare small), we allow the user to select data items from a\ndialog. Firstly, the user selects a dimension name from a name\nlist in the dialog. Then a brief summary of the dimensions\nwill be provided to help the user set up the selection criteria\nfor the selected dimension. If the dimension is a categorical\ndimension, the distinct values in that dimension as well as the\nnumber of data items for each value will be provided. The user\ncan then select the desired distinct values. If the dimension is\na numeric dimension, a histogram of the dimension will be\nprovided. The user then set up a minimum value and maximum\nvalue for the selection using two sliders. The user can set the\nselection ranges for multiple dimensions.\n\nAfter the user sets the selection criteria, he/she can click a\nbutton in the dialog to trigger the selection. A problem here is\nhow to highlight the selected data items. In most visualization\nsystems, selected data items are highlighted using either a\nspecial color, or a surrounding box around the selected items.\nHowever, in the VaR display with pixel-oriented techniques,\ncolor has been used to represent the values, and it is hard\nto put a surrounding box in a condensed glyph, especially if\nthe selected data items are not adjacent to each other in the\nglyphs.\n\nA straightforward solution to this problem is to display only\nthe selected data items. This is a general solution suitable for\nall realizations of the VaR display. However, a drawback of\nthis approach is that the context provided by unselected data\nitems is lost. Such a context is often useful. For example, the\nusers might want to compare the selected data items with the\nunselected data items among the dimensions.\n\nIn order to overcome this drawback, we developed an\napproach called data item masking. This approach is only\nuseful for VaR displays using pixel-oriented techniques. In\n\n\x0c9\n\nFig. 6. Labeling Solutions (a) All dimensions are labeled with names (b) Dimensions selected by the labeling algorithm are labeled. Clutter is reduced. (c)\nAngled text is used to label all dimensions in the Jigsaw map layout. The dataset is the Image-89 dataset.\n\naccording to the following two heuristic criteria: 1) they should\nbe distinct dimensions, i.e., two similar dimensions should\nnot be labeled at the same time. Dimensions distinct from all\nother labeled dimensions should be labeled. 2). they should be\nseparated from each other as much as possible to avoid clutter\non the screen. In addition, we allow users to interactively\nchange the number of dimensions labeled to get a less cluttered\nview or to see more labels.\n\nCriterion 1 is exactly the criterion used for automatic se-\nlection of separated dimensions (see Section VII-C). Criterion\n2 adds more constraints to the selection. Recall that there is\nsome freedom in step 4 of the selection algorithm, i.e., any\ndimensions in the candidate dimension set can be selected; we\nmodi\ufb01ed the algorithm for labeling as follows:\n\n1) Assign a dimension and a selection threshold.\n2) Set the assigned dimension as \u201cselected\u201d and all other\n\ndimensions as \u201cunselected\u201d.\n\n3) Find all unselected dimensions whose correlations with\nall existing selected dimensions are smaller than the\nthreshold. Mark them as \u201ccandidates\u201d.\n\n4) If there is no candidate dimension, go to step 5. Else, set\nthe candidate dimension which is the most far way on\nthe screen from its closest existing selected dimension\nas \u201cselected\u201d and other candidates as \u201cunselected\u201d. Go\nback to step 3.\n\n5) Return all dimensions marked as \u201cselected\u201d and label\n\nthis approach, both selected and unselected data items are\ndrawn on the screen. Unselected data items are covered by\na mask. Users can interactively change the color of the mask,\nand adjust the transparency of the mask though a slider. When\nthe mask is opaque, as shown in Figure 5b, unselected data\nitems are hidden. When the mask is fully transparent, as shown\nin Figure 5a, the selected data items are not highlighted. When\nthe mask is semi-transparent, as show in Figure 5c, the selected\ndata items are highlighted within the context provided by\nthe unselected data items. Users can interactively change the\ntransparency of the mask to adjust the strength of the context.\nThe implementation of this masking operation is simple.\nFirst, a mask is generated using an approach similar to the\ngeneration of a normal dimension glyph. The only difference\nis that the pixels are set to be transparent for selected data\nitems and with user assigned color and transparency for\nunselected data items. Our mask generation mechanism has\nno dependency on the order of the data items,\nis\nnot necessary for the selected data items to be adjacent to\neach other in the glyphs. Since the color and shape of the\nmasks are the same for all\nthe mask is only\ngenerated once, stored as a texture object, and pasted in the\nfront of all the glyphs. Since the texture mapping operation is\nef\ufb01cient in OpenGL, displaying masks has minimal effect on\nthe rendering of a VaR display.\n\nthe glyphs,\n\ni.e.,\n\nit\n\nVIII. LABELING\n\nthem.\n\nIn the original version of the VaR display, dimension names\nare labeled horizontally in the middle top region above the\ndimension glyph for all dimensions shown on the screen (see\nFigure 6a). The labels clutter the screen seriously for a high\ndimensional dataset, thus we did not provide the labeling\noption to users. Rather, when users moved the cursor over\na glyph, the glyph name showed in the message bar below\nthe display. However, users complained that \ufb01nding dimension\nnames in this way was tiring. They argued that the VaR display\nwithout dimension labels is much less meaningful than one\nwith names labeled. In order to solve this problem, we chose to\nlabel a subset of dimensions on the screen for the MDS layout\n(see Figure 6b). The dimensions to be labeled are selected\n\nWhen calculating the screen distance between two dimen-\nsions in step 4, we must consider the fact that horizontal labels\nare used. Their lengths are much larger than their widths.\nAssume that labels have 5 characters on average and the\ncharacters have equal height and width, the screen distance\nbetween two dimensions d1 and d2 D(d1, d2) = fabs((d1.x\n- d1.x)) + 5 * fabs((d1.y - d2.y)), where x and y are the\nscreen coordinates of the dimensions. The equation means that\nwe prefer dimensions separated in the vertical direction than\nthe horizontal direction. Figure 6b shows the same display as\nFigure 6a with selected dimensions labeled using the above\nalgorithm.\n\nThe same labeling approach can be applied to the Jigsaw\n\n\x0cmap layout. In addition, since the glyphs are placed in a regular\nmesh in the Jigsaw map, applying an angle on all the labels\ngreatly reduces the clutter on the screen even when all labels\nare shown. Figure6c shows the Image-89 datasets in the Jigsaw\nmap layout with all dimension names displayed at a 20 degree\nangle. Almost all of the dimension names can be distinguished\nfrom this display.\n\nIn our prototype we bind labeling with selections,\n\ni.e.,\nusers have the option to show labels of selected dimensions\nonly. When a user chooses this option and uses the automatic\nselection tool for separated dimensions, it is exactly the above\nclutter-reducing labeling approach. When a user uses the\nselection tool for related dimensions, the dimensions closely\nrelated to the user-assigned dimensions are labeled (see Figure\n3d for an example).\n\nIX. IMPLEMENTATION AND SCALABILITY ISSUE\n\nWhen there are several hundred dimensions, the datasets\ncan easily contain millions of data values even if they only\ncontain thousands of data items. Datasets often have a higher\nnumber of data items. Such large datasets not only cause large\nresponse time during interactions and problems in storing the\ndata structures in a visualization system, but also cause clutter\non the display. Scalability is a critical issue for visualization\nsystems aimed at high dimensional datasets.\n\nWe have implemented a fully working prototype of the VaR\ndisplay. The biggest dataset that has been successfully loaded\ninto the VaR display so far is an image classi\ufb01cation dataset\ncontaining 838 dimensions and 11413 data items, which means\nover 9 million data values (see Figure 3 for its VaR display).\nMost interactions can be processed within a few seconds on a\ntypical PC for this dataset. This dataset is the biggest dataset\nwe currently have. In the future, we will test larger datasets\non the prototype.\n\nThe critical techniques we used in the prototype for increas-\ning scalability are texture mapping, binning, and sampling\ntechniques. Using the texture mapping techniques provided by\nOpenGL, our prototype stores all dimension glyphs (including\nthe mask in the masking operation) as texture objects and\npastes them on the screen as needed. As long as the glyph\ntextures do not change,\nthe dataset does not need to be\nrescanned, which is time consuming for large datasets. By\nkeeping the texture objects small (such as hundreds of pixels),\nwhich is reasonable since each dimension glyph will not be\ntoo big on the screen in order to reduce clutter, the system can\ndraw hundreds of dimension glyph textures on the screen in\nalmost real time. This approach greatly reduces the response\ntime for most interactions because, except for reordering for\npixel-oriented glyphs and resetting the X dimension for X-Ray\nscatterplot glyphs, almost all other interactions do not change\nthe glyph textures. Rather, they refresh, resize, reposition, or\nreorder the glyphs.\n\nAccording to our experience, drawing fonts in OpenGL is\na time consuming task. Our prototype stores all dimension\nname labels as texture objects. These texture labels are created\none time, and can be quickly pasted on the screen until users\nchange the contents or colors of the labels. The texture labels\ncan be scaled and rotated easily on the screen.\n\n10\n\nBinning, i.e., using buckets to stored statistic information\nabout groups of values rather than recording them individually,\nis an approach widely used in data mining techniques for large\ndatasets. We use binning techniques to increase the speed of\nthe correlation calculation algorithm (see section VI) and the\nX-Ray scatterplot glyph generation (see section IV).\n\nThe prototype stores datasets in an Oracle database server.\nIt dynamically requests data from the server when needed,\nmaking use of the sorting and query functions provided by\nthe database server. When generating a VaR display for a\ndataset containing a large number of data items, we use a\nrandom sampling approach to reduce the response time for\nfetching data items from the server, as well as the number\nof values to be processed. In particular, the system keeps a\ndefault maximum number. When the number of data items\ncontained in a dataset exceeds it, a uniform random sampling\nis performed on the dataset to only fetch the maximum number\nof data items. Users are allowed to interactively adjust the\nmaximum number in order to trade between the response time\nand visualization accuracy.\n\nRandom sampling is easy to implement. However, it has\nthe big drawback that a large sampling rate is needed in order\nto reduce small group loss in the samples [6]. In order to\novercome this problem, many solutions have been proposed,\nsuch as biased sampling [14] or dynamic sample selection\n[2]. It has been shown in the literatures that these approaches\nsuccessfully reduce small group loss. We will explore these\napproaches in the future.\n\nX. DISCUSSION\n\nThe VaR display can serve as an overview tool for a high\ndimensional dataset. Starting from the VaR display, other\nvisualization techniques can be used for more detailed visual\nanalysis. For example, the VaR display is coordinated with\nparallel coordinates, star glyphs, and scatterplot matrix views\nin our prototype. Although these techniques could not handle\nhundreds of dimensions, they work well in examining data\nitems and dimensions selected by the VaR display. Recently,\nwe completed an interesting project in coordinating the VaR\ndisplay with an image exploration interface. The VaR display\nwas used to show the high dimensional image content anno-\ntations. Users were allowed to select images by contents from\nthe VaR display. The images were then examined in detail in\nan image exploration interface. This work is described in [26].\nThe MDS and Jigsaw map glyph layout approaches have\ntheir advantages and disadvantages. From its nature, MDS\nis better in capturing high dimensional relationships than the\nhierarchical approach. However, the non-overlap feature of the\nJigsaw map layout makes it a popular approach for users of\nthe VaR display thus far.\n\nAlthough the pixel-oriented glyphs are mentioned less than\nthe X-Ray scatterplot glyphs in this paper, this is only because\nthe usage of the pixel-oriented techniques has been widely\nstudied and their effectiveness has been shown in many papers.\nCompared to scatterplots, the pixel-oriented glyphs are more\neffective in pixel usage since they make use of each pixel.\nHowever, it is easier to compare the relationship between a\n\n\x0c11\n\nFig. 7.\n(a) The Pixel MDS VaR display of the Image-838 dataset with separated dimensions selected and labeled. (b)(c) The X-Ray scatterplot Jigsaw map\nVaR display of the Image-89 dataset. The dimension in a yellow frame is non-linearly related to the X dimension. (c) The X-Ray scatterplot Jigsaw map VaR\ndisplay with another X dimension (the dimension highlighted by the yellow frame in (b)).\n\ndimension of interest and all other dimensions using the scat-\nterplot glyphs. Users \ufb01nd it dif\ufb01cult to compare the patterns\nof pixel-oriented glyphs if they are far from each other.\n\nCompared to scatterplot matrices, the X-Ray scatterplot VaR\ndisplay has its advantages and disadvantages. For datasets with\na small number of dimensions, scatterplot matrices might be\npreferred since all possible axis-parallel 2-D projections are\nprovided in them. However, for datasets with tens, hundreds\nor thousands of dimensions, the X-Ray scatterplot VaR display\nmight be preferred since it causes less clutter. Its disadvantage\nthat only part of possible 2-D projections are displayed is\nleveraged by two facts: \ufb01rst, dimension relationships conveyed\nby the VaR display give strong hints on the shapes of the\nundisplayed 2-D projections; second, users can interactively\naccess 2-D projections of interest through interactions.\n\nCompared to approaches that rank the 1D or 2-D projections\naccording to their features and allow users to examine detail\nof a projection by selecting it from diagrams or lists conveying\nthe ranking (such as the rank-by-feature framework [19]),\nthe VaR display also has its advantages and disadvantages.\nObviously for tasks such as \ufb01nding the most linearly corre-\nlated dimensions the ranking approaches are better choices.\nHowever, the VaR display is better in helping users grasp the\nglobal relationships among the dimensions.\n\nXI. CASE STUDY\n\nWe have explored several real datasets using the VaR dis-\nplay, including the Image-838 dataset [8] with 838 dimensions\nand 11,413 data items and the Image-89 dataset [8] with 89\ndimensions and 10,471 data items. They all contain low level\nvisual attributes for image classi\ufb01cation. Image analysts are\ninterested in \ufb01nding outlier dimensions that are uncorrelated to\nmost other dimensions, and dimensions representing a group of\ncorrelated dimensions (a dimension cluster) in order to reduce\nthe number of low level visual attributes used in the image\nclassi\ufb01cation process.\n\nFor both datasets, we selected a Pixel MDS VaR display\nwith all dimensions displayed as the initial view, since the\n\npixel-oriented glyphs have a higher pixel usage ef\ufb01ciency\nand the MDS display conveys dimension relationships more\naccurately than the Jigsaw map layout. Figure 7a and Figure 1b\nshow the Pixel MDS VaR displays of the Image-838 dataset\nand the Image-89 dataset respectively. From the \ufb01gures, we\nfound that there are dimension outliers and clusters in both\ndatasets. We then applied automatic selections for separated\ndimensions. Both outlier dimensions and dimensions repre-\nsenting dimension clusters were selected.\n\nThen, we switched to the Jigsaw map layout. Figure 3a\nshows the Pixel Jigsaw map VaR display of the Image-838\ndataset. There are several distinguishable regions that can be\nseen in the map where adjacent glyphs in the regions have\nsimilar patterns. For example, there is a distinguishable region\ncomposed of bright blue glyphs at the left bottom of the\nmap. If only one dimension is selected in such a region, it\nmeans that the neighbors of the selected dimension are closely\nrelated to it, since selection for separated dimensions was used.\nThus they are a dimension cluster and the selected dimension\ncan represent the cluster. The selected and labeled dimension\nangle 135 at the left bottom corner is such a representative\ndimension. Meanwhile, selected dimensions crowded together,\nsuch as the selected dimensions in the left top of the map,\nare potential outliers since they are distinct from their closest\nneighbors. The selected and labeled dimension Coarseness at\nthe left top corner is such suspicious outlier.\n\nIn order to examine if dimension Coarseness is an outlier,\nan X-Ray scatterplot VaR display was created using it as\nthe X dimension (see Figure 3b). From scatterplots in Figure\n3b it can be seen that no other dimensions show strong\ncorrelations with dimension Coarseness. Thus it is con\ufb01rmed\nthat dimension Coarseness is an outlier dimension.\n\nFigure 3c examines if dimension angle 135 is a repre-\nsentative dimension. The X dimension of the scatterplots is\ndimension angle 135 and dimensions closely correlated to\ndimension anagle 135 are selected and highlighted. It can be\nseen that a large number of dimensions are selected and they\nall contain a clear diagonal pattern which indicates a strong\n\n\x0clinear correlation. Figure 3d shows a zoomed in display of the\nselected dimensions in which their labels are shown.\n\nA similar exploration approach was conducted for the\nImage-89 dataset. An interesting pattern in this dataset was\nfound when we were examining dimension Channel Energy 5\nusing the X-Ray scatteplot Jigsaw map VaR display (Figure\n7b): there was a glyph with a curved band (the glyph with a\nyellow frame, the frame was manually added into the \ufb01gure\nfor highlighting). It seemed that\nthis dimension was non-\nlinearly related to the target dimension. It raised our interest\nand became our next target.\n\nWe clicked this dimension to set it as the X dimension in\nthe X-Ray scatterplots and got Figure 7c. It is labeled in\nFigure 7c as Texture Brightness DC. Figure 7c shows that\ndimension Texture Brightness DC is non-linearly related to\nmost dimensions in this dataset. The curved bands are fairly\nthin in some dimensions, which means strong non-linear\nrelationships.\n\nXII. USER STUDY\n\nA user study has been conducted to evaluate the VaR display\nby comparing it to the Rank-by-Feature feature of HCE [19].\nTo form a comparable study, we considered the X-Ray scat-\nterplot glyph style of VaR and the scatterplot prism from the\nHCE system, namely its 2D projection ranking, selection and\nvisualization feature. In HCE, 2D projections are ranked by\nfeatures such as strength of linear relationship or least square\nerror for curvilinear regression. The ranking is visualized in\nboth a matrix and a list. A window beside the ranking windows\nshows the scatterplot of the 2D projection selected by the user.\nOur assumption was that the VaR display would better help\nusers grasp global relationships among the dimensions in a\nhigh dimensional dataset. The reason is that VaR provides a\ndetailed view of all dimensions at the same time while users\nof HCE need to take efforts to associate multiple dimensions\nsince they can only examine a few detailed views at the same\ntime.\n\nEight subjects participated in the user study. The subjects\nvary in educational backgrounds: one was a psychology grad-\nuate student, two were computer science undergraduate stu-\ndents, three were graduate students in the \ufb01eld of visualization,\nand two were researchers/post-doctorates in visualization. The\nsubjects completed the user study one by one on the same\ncomputer with the same instructor. Each subject tested both\nsystems. The order of using VaR and HCE was alternated for\nthe subjects.\n\nThe study began with a 10 minute training session using\nboth VaR and HCE and a further 10 minutes to allow subjects\nto explore the tools and ask the instructor questions. A set of\ntasks were then completed by the subjects using both tools. A\npost-test survey to \ufb01nd user preferences and a discussion were\nconducted immediately following the completion of the tasks.\nWe used the Image-89 dataset of 89 dimensions and 10,471\ndata items. As shown in the case study (Section XI), there\nare some strong linearly related dimensions and some strong\nnon-linearly related dimensions in the Image-89 dataset.\n\nThe \ufb01rst\n\ntask was to describe relationships between a\ngiven dimension and each of the other dimensions using the\n\n12\n\nscatterplot displays by approximating the numbers of different\nscatterplot shapes involved with the given dimension. Samples\nof typical shapes, such as diagonal thin straight bands for lin-\near relations, curved bands for non-linear relations, and evenly\ndistributed scatterplot indicating unrelated dimensions were\nprovided to users. The second task required users to describe\nrelationships among \ufb01ve randomly assigned dimensions using\ntheir scatterplot shapes.\n\nThe majority of users performed the \ufb01rst task quicker and\nevaluated the task to be easier using the VaR display. The\naverage time was 3.2 minutes and the standard deviation was\n0.5 minutes for VaR, and the average time was 4.7 minutes\nand the standard deviation was 3.2 minutes for HCE. On a\nscale of 0 (hard) to 5 (easy), the mean scores of 3.5 and 2.1\nwere given to VaR and HCE respectively. A similar trend was\nidenti\ufb01ed in the second task: the average time was 3.5 minutes\nand the standard deviation was 0.4 minutes for VaR, and the\naverage time was 8.5 minutes and the standard deviation was\n2.9 minutes for HCE. The scores are 3.6 for VaR and 1.0 for\nHCE. Results from these tasks highlighted the advantage of\nthe VaR display in providing a global view of the dimension\nrelationships.\n\nQualitative results and qualitative feedback from the post-\ntest survey were also encouraging. Users typically preferred\nusing VaR over HCE for the given tasks. The reasons given\nby each user were generally similar and can be summarized by\nthe ability to examine details of multiple relations on a single\ndisplay. One user in the study preferred HCE over VaR due to\nthe more detailed and visible scatterplots in the HCE system.\nUsers were also asked if they agreed with the statement \u201cthis\ntool is useful for exploring high dimensional data\u201d. On a scale\nof 0 (disagree) to 5 (agree), users responded with a mean score\nof 4.3 and 3.5 for VaR and HCE respectively.\n\nA number of comments and suggestions were made by the\nusers regarding both systems. Positive feedback from VaR\nincluded an intuitive interface, the instantaneous global view\nand ability to quickly select the X dimension of all scatterplots.\nImprovements suggested by the users involved ranking the\ndimensions by features, and using color and best-\ufb01t-lines to\nenhance the scatterplot displays which were considered too\ndense. In addition, users suggested ordering the dimension\nglyphs according to the shapes of the scatterplot using au-\ntomatic image analysis techniques. For the HCE system, users\npreferred the ranking features and the scatterplot display with\nrich features and interactions. Users suggested that the global\nview provided by the prism in HCE lacked details compared\nto the VaR display. Future work may bene\ufb01t by combining the\nbest features of these two systems.\n\nXIII. CONCLUSION\n\nIn this paper, the VaR display, which allows users to inter-\nactively explore large datasets with hundreds of dimensions,\nwas presented. The essential\nidea of the VaR display is\nto represent each dimension in a high dimensional dataset\nusing an information-rich glyph, and arranging the glyphs to\nreveal the relationships among the dimensions. By integrating\nexisting techniques such as MDS, Jigsaw map, pixel-oriented\n\n\x0c13\n\n[12] D.A. Keim. Designing pixel-oriented visualization techniques: Theory\nIEEE Transactions on Visualization and Computer\n\nand applications.\nGraphics, 6(1):1\u201320, January-March 2000.\n\n[13] D.A. Keim, H.-P. Kriegel, and M. Ankerst. Recursive pattern: a\ntechnique for visualizing very large amounts of data. Proc. IEEE\nVisualization \u201995, pages 279\u2013286, 1995.\n\n[14] G. Kollios, D. Gunopulos, N. Koudas, and S. Berchtold. Ef\ufb01cient\nbiased sampling for approximate clustering and outlier detection in large\nIEEE Transactions on Knowledge and Data Engineering,\ndata sets.\n15(5):1170\u20131187, 2003.\n\n[15] J.B. Kruskal and M. Wish. Multidimensional Scaling. Sage Publications,\n\n1978.\n\n[16] A. MacEachren, X. Dai, F. Hardisty, D. Guo, and G. Lengerich. Explor-\ning high-d spaces with multiform matrices and small multiples. Proc.\nIEEE Symposium on Information Visualization, pages 31\u201338, 2003.\n\n[17] F. Murtagh. A survey of recent advances in hierarchical clustering\n\nalgorithms. Computer Journal, 26(4):354\u2013359, 1983.\n\n[18] NetMBA.\n\nhttp://www.netmba.com/statistics/plot/scatter/.\n\n[19] J. Seo and B. Shneiderman. A rank-by-feature framework for un-\nsupervised multidimensional data exploration using low dimensional\nprojections. Proc. IEEE Symposium on Information Visualization, pages\n65\u201372, 2004.\n\n[20] J. Seo and B. Shneiderman. A rank-by-feature framework for inter-\nactive exploration of multidimensional data. Information Visualization,\n4(2):96\u2013113, 2005.\n\n[21] B. Shneiderman. Tree visualization with tree-maps: A 2d space-\ufb01lling\n\napproach. ACM Transactions on Graphics, 11(1):92\u201399, Jan. 1992.\n\n[22] M.O. Ward. A taxonomy of glyph placement strategies for multidi-\nmensional data visualization. Information Visualization, 1(3-4):194\u2013210,\n2002.\n\n[23] M. Wattenberg. A note on space-\ufb01lling visualizations and space-\ufb01lling\ncurves. Proc. IEEE Symposium on Information Visualization, pages 181\u2013\n186, 2005.\n\n[24] E.J. Wegman and Q. Luo. High dimensional clustering using parallel\ncoordinates and the grand tour. Computing Science and Statistics,\n28:361\u2013368, 1997.\n\n[25] J.A. Wise, J.J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur,\nand V. Crow. Visualizing the non-visual: Spatial analysis and interaction\nwith information from text documents. Proc. IEEE Symposium on\nInformation Visualization, pages 51\u201358, 1995.\n\n[26] J. Yang, J. Fan, D. Hubball, Y. Gao, H. Luo, W. Ribarsky, and\nM. Ward. Semantic image browser: Bridging information visualization\nwith automated intelligent image analysis. Proc. IEEE Symposium on\nVisual Analytics Science and Technology, pages 191\u2013198, 2006.\n\n[27] J. Yang, A. Patro, S. Huang, N. Mehta, M. Ward, and E. Rundensteiner.\nValue and relation display for interactive exploration of high dimensional\ndatasets. Proc. IEEE Symposium on Information Visualization, pages\n73\u201380, 2004.\n\n[28] J. Yang, M.O. Ward, E.A. Rundensteiner, and S. Huang. Visual\nhierarchical dimension reduction for exploration of high dimensional\ndatasets. Eurographics/IEEE TCVG Symposium on Visualization, pages\n19\u201328, 2003.\n\n[29] J. Yi, R. Melton, J. Stasko, and J. Jacko. Dust & magnet: Multivariate\ninformation visualization using a magnet metaphor. Information Visual-\nization, 4:239\u2013256, 2005.\n\ntechniques, and scatterplots, and allowing users to interactively\nexplore large datasets according to their interests, the VaR\ndisplay provides a rich metaphor for interactive exploration\nof high dimensional datasets. The case studies and user study\nconducted proved that the VaR display is an effective approach\nwith high scalability.\n\nAlthough work presented in this paper has greatly extended\nthe functionality of the original VaR display [27], we believe\nthat\nthe VaR display still has much potential for further\ndevelopment. Time-dependant dimension glyph generation or\nlayout, the ability to convey spatial information, and the ability\nto visualize dynamically changing data streams, are future\ndirections we want to explore in the VaR display. In addition,\ndetecting features by analyzing and comparing textures of\ndimension glyphs using automatic image analysis techniques\nis also an appealing future work. Another important future\nwork is to conduct user studies to evaluate different options\nprovided by the VaR display.\n\nACKNOWLEDGMENT\n\nWe gratefully thank Dr. Daniel A. Keim for giving many\nvaluable suggestions for this work, Dr. Jianping Fan, Yuli Gao,\nand Hangzai Luo for providing us the datasets, and the users\nwho participated in the user study.\n\nThis work was performed with partial support from NSF\ngrant IIS-0119276 and the National Visualization and Ana-\nlytics Center (NVAC(tm)), a U.S. Department of Homeland\nSecurity Program, under the auspices of the Southeastern Re-\ngional Visualization and Analytics Center. NVAC is operated\nby the Paci\ufb01c Northwest National Laboratory (PNNL), a U.S.\nDepartment of Energy Of\ufb01ce of Science laboratory.\n\nREFERENCES\n\n[1] M. Ankerst, S. Berchtold, and D.A. Keim. Similarity clustering of\ndimensions for an enhanced visualization of multidimensional data.\nProc. IEEE Symposium on Information Visualization, pages 52\u201360,\n1998.\n\n[2] B. Babcock, S. Chaudhuri, and G. Das. Dynamic sample selection\nfor approximate query processing. Proc. ACM SIGMOD International\nConference on Management of Data, pages 539\u2013550, 2003.\n\n[3] B. Bederson, B. Shneiderman, and M. Wattenberg. Ordered and quantum\ntreemaps: Making effective use of 2d space to display hierarchies. ACM\nTransactions on Graphics, 21(4):833\u2013854, 2002.\n\n[4] C.L. Bentley and M.O. Ward. Animating multidimensional scaling\nto visualize n- dimensional data sets. Proc. IEEE Symposium on\nInformation Visualization, pages 72\u201373, 1996.\n\n[5] K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is \u201cnearest\nneighbor\u201d meaningful? Lecture Notes in Computer Science, 1540:217\u2013\n235, 1999.\n\n[6] S. Chaudhuri, R. Motwani, and V. Narasayya. Random sampling for\nhistogram construction: how much is enough? Proc. ACM SIGMOD\nInternational Conference on Management of Data, pages 436\u2013447, 1998.\n[7] W.S. Cleveland and M.E. McGill. Dynamic Graphics for Statistics.\n\nWadsworth, Inc., 1988.\n\n[8] J. Fan, Y. Gao, and H. Luo. Multi-level annotation of natural scenes\nusing dominant image components and semantic image concepts. Proc.\nACM international conference on Multimedia, pages 540 \u2013 547, 2004.\nInteractive information visualization of\na million items. Proc. IEEE Symposium on Information Visualization,\npages 117\u2013124, 2002.\n\n[9] J.-D. Fekete and C. Plaisant.\n\n[10] Y. Fua, M.O. Ward, and E.A. Rundensteiner. Hierarchical parallel\ncoordinates for exploration of large datasets. Proc. IEEE Visualization,\npages 43\u201350, Oct. 1999.\n\n[11] B. Hibbard and D. Santek. The vis-5d system for easy interactive\n\nvisualization. Proc. IEEE Visualization, pages 28\u201335, 1990.\n\nView publication stats\nView publication stats\n\n\x0c',
'notes': u'<p>They show a system to visualize hundreds of dimensions using metafors.</p>\n<p>&nbsp;</p>\n<p>Could be a citable paper or could be a paper to get some ideas from for an attraction 2 paper.</p>', 
'pdf_file': u'WSWI9XMV', 
'clusterID': False, 
'citationArticles': False, 
'pages': False, 
'parent_item': u'7N8IFD7Z', 
'citations': False, 
'user': 'self.user', 
'organization': False, 
'year': 2007, 
'versions': False, 
'type': u'journalArticle', 
'abstract': False, 
'tags': u"[{u'tag': u'metafor'}, {u'tag': u'multidimensional data'}, {u'tag': u'visualization'}]"
}